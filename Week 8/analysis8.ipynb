{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://statsapi.mlb.com/api/v1/teams/119/roster?season=2024\"\n",
    "response = requests.get(url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybaseball\n",
    "from pybaseball import statcast\n",
    "\n",
    "pybaseball.cache.enable()\n",
    "\n",
    "data = statcast('1968-03-01', '1971-10-30')\n",
    "data.to_csv('baseball_analysis15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = \"../data\" \n",
    "csv_files = [os.path.join(data_folder, file) for file in os.listdir(data_folder) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "df_list = [pd.read_csv(file, na_values=[\"N/A\", \"null\", \"\"]) for file in csv_files]\n",
    "concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "concatenated_df.to_csv(\"analysis_baseball.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 with 326281 rows...\n",
      "Processing batch 2 with 325599 rows...\n",
      "Processing batch 3 with 327491 rows...\n",
      "Processing batch 4 with 327239 rows...\n",
      "Processing batch 5 with 330639 rows...\n",
      "Processing batch 6 with 331593 rows...\n",
      "Processing batch 7 with 332094 rows...\n",
      "Processing batch 8 with 331220 rows...\n",
      "Processing batch 9 with 330506 rows...\n",
      "Processing batch 10 with 327535 rows...\n",
      "Processing batch 11 with 327859 rows...\n",
      "Processing batch 12 with 325406 rows...\n",
      "Processing batch 13 with 325846 rows...\n",
      "Processing batch 14 with 325949 rows...\n",
      "Processing batch 15 with 325316 rows...\n",
      "Processing batch 16 with 325436 rows...\n",
      "Processing batch 17 with 326256 rows...\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "In CSV column #37: CSV conversion error to null: invalid value '75.38'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m parquet_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_reader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing batch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m with \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrecord_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m rows...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/ipc.pxi:671\u001b[0m, in \u001b[0;36mpyarrow.lib.RecordBatchReader.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/ipc.pxi:705\u001b[0m, in \u001b[0;36mpyarrow.lib.RecordBatchReader.read_next_batch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: In CSV column #37: CSV conversion error to null: invalid value '75.38'"
     ]
    }
   ],
   "source": [
    "import pyarrow.csv as pv\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import polars as pl\n",
    "\n",
    "csv_file = \"../data/analysis_baseball.csv\"\n",
    "parquet_file = \"../data/baseball_analysis.parquet\"\n",
    "\n",
    "BLOCK_SIZE = 120_000_000\n",
    "\n",
    "read_options = pv.ReadOptions(block_size=BLOCK_SIZE)\n",
    "csv_reader = pv.open_csv(csv_file, read_options=read_options)\n",
    "\n",
    "parquet_writer = None\n",
    "\n",
    "try:\n",
    "    for i, record_batch in enumerate(csv_reader):\n",
    "        print(f\"Processing batch {i+1} with {record_batch.num_rows} rows...\")\n",
    "        table = pa.Table.from_batches([record_batch])\n",
    "        if parquet_writer is None:\n",
    "            parquet_writer = pq.ParquetWriter(\n",
    "                parquet_file, schema=record_batch.schema, compression=\"snappy\", use_dictionary=True\n",
    "            )\n",
    "        parquet_writer.write_table(table)\n",
    "\n",
    "\n",
    "\n",
    "finally:\n",
    "    if parquet_writer:\n",
    "        parquet_writer.close()\n",
    "\n",
    "print(f\"Successfully converted {csv_file} to {parquet_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyathena import connect\n",
    "\n",
    "conn = connect(\n",
    "    s3_staging_dir=\"s3://calpolyvideo/query-results/\",  \n",
    "    region_name=\"us-west-1\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "s3_bucket = \"calpolyvideo\"\n",
    "csv_file_key = \"raw_data/analysis_baseball.csv\"\n",
    "parquet_file_key = \"processed_data/large_file.parquet\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "chunk_size = 100000  \n",
    "parquet_buffer = BytesIO()\n",
    "\n",
    "for chunk in pd.read_csv(f\"s3://{s3_bucket}/{csv_file_key}\", chunksize=chunk_size):\n",
    "    chunk.to_parquet(parquet_buffer, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "s3.put_object(Bucket=s3_bucket, Key=parquet_file_key, Body=parquet_buffer.getvalue())\n",
    "\n",
    "print(\"✅ CSV successfully converted to Parquet in chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(\n",
    "     s3_staging_dir=\"s3://calpolyvideo/query-results/\",  \n",
    "     region_name=\"us-west-1\") \n",
    "query = \"SELECT events FROM my_database.analysis_baseball_csv LIMIT 10;\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8de22873249422789e85587f232cfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>launch_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030613</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030614</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030615</th>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030616</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030617</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2030618 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        launch_angle\n",
       "0               59.0\n",
       "1               46.0\n",
       "2               40.0\n",
       "3               23.0\n",
       "4               35.0\n",
       "...              ...\n",
       "2030613         54.0\n",
       "2030614         10.0\n",
       "2030615        -22.0\n",
       "2030616          7.0\n",
       "2030617          0.0\n",
       "\n",
       "[2030618 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb as db\n",
    "\n",
    "file_path =  \"../data/analysis_baseball.csv\"\n",
    "\n",
    "result0 = db.query(f\"\"\"SELECT launch_angle\n",
    "                    FROM '{file_path}'\n",
    "                    WHERE launch_angle IS NOT NULL\n",
    "                    ORDER BY game_date ASC;\"\"\")\n",
    "df0 = result0.to_df()\n",
    "df0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
